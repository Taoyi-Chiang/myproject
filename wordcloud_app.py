import streamlit as st
import pandas as pd
import jieba
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import numpy as np

# ğŸ¯ å‡ç´šç‰ˆï¼šæ•´åˆå¼ Section åˆ†æå™¨ï¼ˆæ–‡å­—é›²ã€é•·æ¢åœ–ã€é›·é”åœ–ã€åœ“é¤…åœ–ï¼‰
st.set_page_config(page_title="åˆ†æç¥å™¨", layout="wide", page_icon="ğŸ“š")

font_path = "C:/Windows/Fonts/msjh.ttc"
font_name = fm.FontProperties(fname=font_path).get_name()
plt.rcParams["font.family"] = font_name

st.title("ğŸ“š ä¸­æ–‡èª²å¤šå…ƒè³‡æ–™åˆ†æå·¥å…·")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šå‚³ CSV æª”æ¡ˆï¼ˆéœ€å« Section é›™å±¤æ¬„ä½ï¼‰", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file, header=[0, 1])

    # å»ºç«‹æ¬„ä½å°æ‡‰å­—å…¸ï¼ˆSection âœ [æ¬„ä½åç¨±æ¸…å–®]ï¼‰
    section_dict = {}
    for (section, question) in df.columns:
        if section == "åŸºæœ¬è³‡æ–™":
            continue
        if section not in section_dict:
            section_dict[section] = []
        section_dict[section].append(question)

    selected_section = st.selectbox("è«‹é¸æ“‡ä¸»é¡Œå€å¡Šï¼ˆSectionï¼‰ï¼š", list(section_dict.keys()))
    section_cols = [(selected_section, q) for q in section_dict[selected_section]]

    # éæ¿¾å™¨ï¼ˆç­ç´š/å­¸ç³»/å¹´ç´šï¼‰
    for key in ["ç­ç´š", "å­¸ç³»", "å¹´ç´š"]:
        df[("åŸºæœ¬è³‡æ–™", key)] = df[("åŸºæœ¬è³‡æ–™", key)].astype(str).str.strip()

    col1, col2, col3 = st.columns(3)
    with col1:
        selected_class = st.multiselect("éæ¿¾ç­ç´šï¼š", sorted(df[("åŸºæœ¬è³‡æ–™", "ç­ç´š")].dropna().unique()))
    with col2:
        selected_dept = st.multiselect("éæ¿¾å­¸ç³»ï¼š", sorted(df[("åŸºæœ¬è³‡æ–™", "å­¸ç³»")].dropna().unique()))
    with col3:
        selected_grade = st.multiselect("éæ¿¾å¹´ç´šï¼š", sorted(df[("åŸºæœ¬è³‡æ–™", "å¹´ç´š")].dropna().unique()))

    filtered_df = df.copy()
    if selected_class:
        filtered_df = filtered_df[filtered_df[("åŸºæœ¬è³‡æ–™", "ç­ç´š")].isin(selected_class)]
    if selected_dept:
        filtered_df = filtered_df[filtered_df[("åŸºæœ¬è³‡æ–™", "å­¸ç³»")].isin(selected_dept)]
    if selected_grade:
        filtered_df = filtered_df[filtered_df[("åŸºæœ¬è³‡æ–™", "å¹´ç´š")].isin(selected_grade)]

    numeric_cols = [col for col in section_cols if pd.api.types.is_numeric_dtype(filtered_df[col])]
    text_cols = [col for col in section_cols if not pd.api.types.is_numeric_dtype(filtered_df[col])]

    # æ•¸å€¼æ¬„ä½ âœ é›·é”åœ–ï¼ˆå¹³å‡å€¼ï¼‰
    if numeric_cols:
        st.markdown("### ğŸ“ˆ æ•¸å€¼æ•´åˆé›·é”åœ–")
        avg_scores = filtered_df[numeric_cols].mean().round(2)
        labels = [q[1] for q in avg_scores.index]
        values = avg_scores.values
        angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
        values = np.concatenate((values, [values[0]]))
        angles += angles[:1]

        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
        ax.plot(angles, values, 'o-', linewidth=2)
        ax.fill(angles, values, alpha=0.25)
        ax.set_thetagrids(np.degrees(angles[:-1]), labels)
        ax.set_title(f"{selected_section} å„é¢å‘å¹³å‡åˆ†æ•¸é›·é”åœ–")
        st.pyplot(fig)

        st.dataframe(avg_scores.reset_index().rename(columns={0: "å¹³å‡åˆ†æ•¸"}))

    # é¡åˆ¥æ¬„ä½ âœ åœ“é¤…åœ–ç¾¤çµ„
    if text_cols:
        st.markdown("### ğŸ§© é¡åˆ¥æ¬„ä½åœ“é¤…çµ±è¨ˆåœ–")
        for col in text_cols:
            data = filtered_df[col].dropna().astype(str)
            if data.nunique() <= 10:
                fig, ax = plt.subplots()
                data.value_counts().plot(kind="pie", autopct="%1.1f%%", ax=ax)
                ax.set_ylabel("")
                ax.set_title(col[1])
                st.pyplot(fig)

        # é¡å¤–æ–‡å­—é›²è¼”åŠ©ï¼ˆåˆä½µæ‰€æœ‰æ–‡å­—æ¬„ä½ï¼‰
        st.markdown("### â˜ï¸ è³ªæ€§è£œå……æ–‡å­—é›²")
        def get_word_freq(series_list):
            words = []
            for s in series_list:
                for text in s.dropna():
                    seg_list = jieba.lcut(str(text))
                    words.extend([w for w in seg_list if len(w) > 1])
            return Counter(words)

        word_freq = get_word_freq([filtered_df[col] for col in text_cols])
        if word_freq:
            wc = WordCloud(font_path=font_path, background_color='white', width=800, height=600)
            wc.generate_from_frequencies(word_freq)
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.imshow(wc, interpolation="bilinear")
            ax.axis("off")
            st.pyplot(fig)
            st.dataframe(pd.DataFrame(word_freq.most_common(20), columns=["è©èª", "å‡ºç¾æ¬¡æ•¸"]))
        else:
            st.info("âš ï¸ æ²’æœ‰è¶³å¤ æ–‡å­—è³‡æ–™å¯ç”¢å‡ºæ–‡å­—é›²ã€‚")